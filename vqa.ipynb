{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:35 Loading dataloader...\n",
      "12:35 Dataloader loaded with 54 VQA samples\n",
      "12:35 Found 21 object categories\n",
      "12:35 Loading models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /shared/home/SSO3984/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/shared/home/SSO3984/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/shared/home/SSO3984/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/shared/home/SSO3984/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "12:35 using MLP layer as FFN\n",
      "12:36 vision_select_layer: -1\n",
      "12:36 ps_version: v2\n",
      "12:36 min_dynamic_patch: 1\n",
      "12:36 max_dynamic_patch: 12\n",
      "12:36 vision_config is None. Initializing the InternVisionConfig with default values.\n",
      "12:36 llm_config is None. Initializing the LlamaConfig config with default values (`LlamaConfig`).\n",
      "12:36 vision_select_layer: -1\n",
      "12:36 ps_version: v1\n",
      "12:36 min_dynamic_patch: 1\n",
      "12:36 max_dynamic_patch: 6\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "12:36 vision_select_layer: -1\n",
      "12:36 ps_version: v2\n",
      "12:36 min_dynamic_patch: 1\n",
      "12:36 max_dynamic_patch: 12\n",
      "12:36 vision_config is None. Initializing the InternVisionConfig with default values.\n",
      "12:36 llm_config is None. Initializing the LlamaConfig config with default values (`LlamaConfig`).\n",
      "12:36 vision_select_layer: -1\n",
      "12:36 ps_version: v1\n",
      "12:36 min_dynamic_patch: 1\n",
      "12:36 max_dynamic_patch: 6\n",
      "12:36 num_image_token: 256\n",
      "12:36 ps_version: v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930536412132405d9f9ccb69681e5009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/home/SSO3984/.local/lib/python3.12/site-packages/accelerate/utils/modeling.py:1614: UserWarning: The following device_map keys do not match any submodules in the model: ['language_model.model.layers.48', 'language_model.model.layers.49', 'language_model.model.layers.50', 'language_model.model.layers.51', 'language_model.model.layers.52', 'language_model.model.tok_embeddings', 'language_model.output']\n",
      "  warnings.warn(\n",
      "12:37 Loading object features...\n",
      "12:37 Features loaded for 21 objects\n",
      "12:37 Feature objects found: ['Caseys friend marlan-man', 'Blippis shoes-shoes', 'Alexs hat-hat', 'Gabs puppy lili-dog', 'Sherry-woman', 'Nikkis car-car', 'Zaks dog coffee-dog', 'Nikkis camper bag-bag', 'Reynards work chair-chair', 'Casey-man', 'Caseys son-man', 'Sherrys road bike-bike', 'Alex-woman', 'Gab-woman', 'Blippi-man', 'Nikki-woman', 'Caseys boosted board-skateboard', 'Zaks dog kona-dog', 'Reynards keyboard-keyboard', 'Alexs everyday bag-bag', 'Zak-man']\n",
      "12:37   - 'Caseys friend marlan-man'\n",
      "12:37   - 'Blippis shoes-shoes'\n",
      "12:37   - 'Alexs hat-hat'\n",
      "12:37   - 'Gabs puppy lili-dog'\n",
      "12:37   - 'Sherry-woman'\n",
      "12:37   - 'Nikkis car-car'\n",
      "12:37   - 'Zaks dog coffee-dog'\n",
      "12:37   - 'Nikkis camper bag-bag'\n",
      "12:37   - 'Reynards work chair-chair'\n",
      "12:37   - 'Casey-man'\n",
      "12:37   - 'Caseys son-man'\n",
      "12:37   - 'Sherrys road bike-bike'\n",
      "12:37   - 'Alex-woman'\n",
      "12:37   - 'Gab-woman'\n",
      "12:37   - 'Blippi-man'\n",
      "12:37   - 'Nikki-woman'\n",
      "12:37   - 'Caseys boosted board-skateboard'\n",
      "12:37   - 'Zaks dog kona-dog'\n",
      "12:37   - 'Reynards keyboard-keyboard'\n",
      "12:37   - 'Alexs everyday bag-bag'\n",
      "12:37   - 'Zak-man'\n",
      "12:37 Name mapping created: {'Caseys friend marlan': 'Caseys friend marlan-man', 'Blippis shoe': 'Blippis shoes-shoes', 'Blippis shoes': 'Blippis shoes-shoes', 'Alexs hat': 'Alexs hat-hat', 'Gabs puppy lili': 'Gabs puppy lili-dog', 'Sherry': 'Sherry-woman', 'Nikkis car': 'Nikkis car-car', 'Zaks dog coffee': 'Zaks dog coffee-dog', 'Nikkis camper bag': 'Nikkis camper bag-bag', 'Reynards work chair': 'Reynards work chair-chair', 'Casey': 'Casey-man', 'Caseys son': 'Caseys son-man', 'Sherrys road bike': 'Sherrys road bike-bike', 'Alex': 'Alex-woman', 'Gab': 'Gab-woman', 'Blippi': 'Blippi-man', 'Nikki': 'Nikki-woman', 'Caseys boosted board': 'Caseys boosted board-skateboard', 'Zaks dog kona': 'Zaks dog kona-dog', 'Reynards keyboard': 'Reynards keyboard-keyboard', 'Alexs everyday bag': 'Alexs everyday bag-bag', 'Zak': 'Zak-man'}\n",
      "12:37 Results will be saved to: results/vqa/OpenGVLab/InternVL3-14B/Thursday_05_12_37_PM\n",
      "12:37 \n",
      "================================================================================\n",
      "12:37 Starting VQA evaluation\n",
      "12:37 ================================================================================\n",
      "12:37 \n",
      "================================================================================\n",
      "12:37 Processing [1/54]\n",
      "12:37 Original label: Casey_Caseys boosted board\n",
      "12:37 Objects to detect: ['Casey', 'Caseys boosted board']\n",
      "12:37 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Casey_and_Caseys boosted board/Casey_Caseys boosted board_1_positive.png\n",
      "12:37   Mapped 'Casey' -> 'Casey-man'\n",
      "12:37   Mapped 'Caseys boosted board' -> 'Caseys boosted board-skateboard'\n",
      "12:37   Found 2 valid objects: ['Casey-man', 'Caseys boosted board-skateboard']\n",
      "12:37 Applied sam mask on dino features\n",
      "12:37   Detected 'Casey-man' with score 0.239\n",
      "12:37   Detected 'Caseys boosted board-skateboard' with score 0.345\n",
      "12:37 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"CASEY\" and the entity enclosed in a red box is called \"CASEY'S BOOSTED BOARD\". Never mention the boxes and their colors. Answer the following question: Is Casey wearing a gray shirt and is Caseys boosted board's arrow pointing to the right? ?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:37 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:37 Ground Truth: Yes and yes.\n",
      "12:37 Prediction: Yes, Casey is wearing a gray shirt, and Casey's Boosted Board has an arrow pointing to the right.\n",
      "12:37 Result: ✓ CORRECT\n",
      "12:37 \n",
      "================================================================================\n",
      "12:37 Processing [2/54]\n",
      "12:37 Original label: Casey_Caseys boosted board\n",
      "12:37 Objects to detect: ['Casey', 'Caseys boosted board']\n",
      "12:37 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Casey_and_Caseys boosted board/Casey_Caseys boosted board_2_positive.png\n",
      "12:37   Mapped 'Casey' -> 'Casey-man'\n",
      "12:37   Mapped 'Caseys boosted board' -> 'Caseys boosted board-skateboard'\n",
      "12:37   Found 2 valid objects: ['Casey-man', 'Caseys boosted board-skateboard']\n",
      "12:37 Applied sam mask on dino features\n",
      "12:37   Detected 'Casey-man' with score 0.187\n",
      "12:37   Detected 'Caseys boosted board-skateboard' with score 0.354\n",
      "12:37 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"CASEY\" and the entity enclosed in a red box is called \"CASEY'S BOOSTED BOARD\". Never mention the boxes and their colors. Answer the following question: Where is Casey standing and what is written on Caseys boosted board ?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:37 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:37 Ground Truth: Casey is standing in a room similar to a workshop and the word Boosted is written on Caseys boosted board\n",
      "12:37 Prediction: Casey is standing in a workshop or garage. The text on Casey's Boosted Board reads \"BOOSTED.\"\n",
      "12:37 Result: ✓ CORRECT\n",
      "12:37 \n",
      "================================================================================\n",
      "12:37 Processing [3/54]\n",
      "12:37 Original label: Casey_Caseys boosted board\n",
      "12:37 Objects to detect: ['Casey', 'Caseys boosted board']\n",
      "12:37 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Casey_and_Caseys boosted board/Casey_Caseys boosted board_3_positive.png\n",
      "12:37   Mapped 'Casey' -> 'Casey-man'\n",
      "12:37   Mapped 'Caseys boosted board' -> 'Caseys boosted board-skateboard'\n",
      "12:37   Found 2 valid objects: ['Casey-man', 'Caseys boosted board-skateboard']\n",
      "12:37 Applied sam mask on dino features\n",
      "12:37   Detected 'Casey-man' with score 0.203\n",
      "12:37   Detected 'Caseys boosted board-skateboard' with score 0.234\n",
      "12:37 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"CASEY\" and the entity enclosed in a red box is called \"CASEY'S BOOSTED BOARD\". Never mention the boxes and their colors. Answer the following question: What is Casey wearing on their eyes and what color are the Caseys boosted board's wheels?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:37 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:37 Ground Truth: Casey is wearing Sunglasses and Caseys boosted board's wheels are orange.\n",
      "12:37 Prediction: Casey is wearing sunglasses, and the wheels of Casey's Boosted Board are orange.\n",
      "12:37 Result: ✓ CORRECT\n",
      "12:37 \n",
      "================================================================================\n",
      "12:37 Processing [4/54]\n",
      "12:37 Original label: Casey_Caseys boosted board\n",
      "12:37 Objects to detect: ['Casey', 'Caseys boosted board']\n",
      "12:37 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Casey_and_Caseys boosted board/Casey_Caseys boosted board_5_positive.png\n",
      "12:37   Mapped 'Casey' -> 'Casey-man'\n",
      "12:37   Mapped 'Caseys boosted board' -> 'Caseys boosted board-skateboard'\n",
      "12:37   Found 2 valid objects: ['Casey-man', 'Caseys boosted board-skateboard']\n",
      "12:37 Applied sam mask on dino features\n",
      "12:37   Detected 'Casey-man' with score 0.254\n",
      "12:37   Detected 'Caseys boosted board-skateboard' with score 0.326\n",
      "12:37 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"CASEY\" and the entity enclosed in a red box is called \"CASEY'S BOOSTED BOARD\". Never mention the boxes and their colors. Answer the following question: What is Casey doing and what is painted on Caseys boosted board?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:37 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:37 Ground Truth: Casey is holding up Caseys boosted board which has a large green arrow painted on it.\n",
      "12:37 Prediction: Casey is riding a Boosted Board. The board has a green design painted on it.\n",
      "12:37 Result: ✗ INCORRECT\n",
      "12:37 \n",
      "================================================================================\n",
      "12:37 Processing [5/54]\n",
      "12:37 Original label: Zak_Zaks dog kona\n",
      "12:37 Objects to detect: ['Zak', 'Zaks dog kona']\n",
      "12:37 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Zak_and_Zaks dog kona/Zak_Zaks dog kona_1_positive.png\n",
      "12:37   Mapped 'Zak' -> 'Zak-man'\n",
      "12:37   Mapped 'Zaks dog kona' -> 'Zaks dog kona-dog'\n",
      "12:37   Found 2 valid objects: ['Zak-man', 'Zaks dog kona-dog']\n",
      "12:37 Applied sam mask on dino features\n",
      "12:37   Detected 'Zak-man' with score 0.385\n",
      "12:37   Detected 'Zaks dog kona-dog' with score 0.284\n",
      "12:37 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ZAK\" and the entity enclosed in a red box is called \"ZAK'S DOG KONA\". Never mention the boxes and their colors. Answer the following question: What is Zak doing and what is Zaks dog kona focused on?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:37 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:37 Ground Truth: Zak is reaching for the dog bowl and Zaks dog kona semms to be eating or sniffing the food.\n",
      "12:37 Prediction: Zak is kneeling on the floor, interacting with his dog, Kona. Kona appears to be focused on something in Zak's hand.\n",
      "12:37 Result: ✓ CORRECT\n",
      "12:37 \n",
      "================================================================================\n",
      "12:37 Processing [6/54]\n",
      "12:37 Original label: Zak_Zaks dog kona\n",
      "12:37 Objects to detect: ['Zak', 'Zaks dog kona']\n",
      "12:37 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Zak_and_Zaks dog kona/Zak_Zaks dog kona_2_positive.png\n",
      "12:37   Mapped 'Zak' -> 'Zak-man'\n",
      "12:37   Mapped 'Zaks dog kona' -> 'Zaks dog kona-dog'\n",
      "12:37   Found 2 valid objects: ['Zak-man', 'Zaks dog kona-dog']\n",
      "12:37 Applied sam mask on dino features\n",
      "12:37   Detected 'Zak-man' with score 0.577\n",
      "12:37   Detected 'Zaks dog kona-dog' with score 0.274\n",
      "12:37 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ZAK\" and the entity enclosed in a red box is called \"ZAK'S DOG KONA\". Never mention the boxes and their colors. Answer the following question: What are Zak and Zaks dog kona wearing?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:37 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:37 Ground Truth: Zak is wearing a gray T-shirt and Zaks dog kona is wearing a pink and black collar.\n",
      "12:37 Prediction: Zak is wearing a gray t-shirt and jeans, while Kona, Zak's dog, is wearing a pink collar.\n",
      "12:37 Result: ✗ INCORRECT\n",
      "12:37 \n",
      "================================================================================\n",
      "12:37 Processing [7/54]\n",
      "12:37 Original label: Zak_Zaks dog kona\n",
      "12:37 Objects to detect: ['Zak', 'Zaks dog kona']\n",
      "12:37 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Zak_and_Zaks dog kona/Zak_Zaks dog kona_3_positive.png\n",
      "12:37   Mapped 'Zak' -> 'Zak-man'\n",
      "12:37   Mapped 'Zaks dog kona' -> 'Zaks dog kona-dog'\n",
      "12:37   Found 2 valid objects: ['Zak-man', 'Zaks dog kona-dog']\n",
      "12:37 Applied sam mask on dino features\n",
      "12:37   Detected 'Zak-man' with score 0.436\n",
      "12:37   Detected 'Zaks dog kona-dog' with score 0.245\n",
      "12:37 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ZAK\" and the entity enclosed in a red box is called \"ZAK'S DOG KONA\". Never mention the boxes and their colors. Answer the following question: What is Zak’s expression and how is Zaks dog kona behaving ?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:37 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:37 Ground Truth: Zak seems to be talking to the camera and Zaks dog kona seems to be focused on something on the floor.\n",
      "12:37 Prediction: Zak appears to be smiling and seems engaged, possibly interacting with his dog. Kona, the dog, is standing attentively, facing Zak, likely anticipating something, such as food from the bowl Zak is holding.\n",
      "12:37 Result: ✗ INCORRECT\n",
      "12:37 \n",
      "================================================================================\n",
      "12:37 Processing [8/54]\n",
      "12:37 Original label: Zak_Zaks dog kona\n",
      "12:37 Objects to detect: ['Zak', 'Zaks dog kona']\n",
      "12:37 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Zak_and_Zaks dog kona/Zak_Zaks dog kona_4_positive.png\n",
      "12:37   Mapped 'Zak' -> 'Zak-man'\n",
      "12:37   Mapped 'Zaks dog kona' -> 'Zaks dog kona-dog'\n",
      "12:37   Found 2 valid objects: ['Zak-man', 'Zaks dog kona-dog']\n",
      "12:37 Applied sam mask on dino features\n",
      "12:37   Detected 'Zak-man' with score 0.478\n",
      "12:37   Detected 'Zaks dog kona-dog' with score 0.200\n",
      "12:37 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ZAK\" and the entity enclosed in a red box is called \"ZAK'S DOG KONA\". Never mention the boxes and their colors. Answer the following question: What are Zak and Zaks dog kona doing?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:37 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:37 Ground Truth: Zaks dog kona is playing with a purple frisbee and Zak is kneeling on the grass.\n",
      "12:37 Prediction: Zak is kneeling on the grass, and his dog Kona is playing with a purple frisbee.\n",
      "12:37 Result: ✓ CORRECT\n",
      "12:37 \n",
      "================================================================================\n",
      "12:37 Processing [9/54]\n",
      "12:37 Original label: Zak_Zaks dog kona\n",
      "12:37 Objects to detect: ['Zak', 'Zaks dog kona']\n",
      "12:37 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Zak_and_Zaks dog kona/Zak_Zaks dog kona_5_positive.png\n",
      "12:37   Mapped 'Zak' -> 'Zak-man'\n",
      "12:37   Mapped 'Zaks dog kona' -> 'Zaks dog kona-dog'\n",
      "12:37   Found 2 valid objects: ['Zak-man', 'Zaks dog kona-dog']\n",
      "12:37 Applied sam mask on dino features\n",
      "12:37   Detected 'Zak-man' with score 0.514\n",
      "12:37   Detected 'Zaks dog kona-dog' with score 0.204\n",
      "12:37 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ZAK\" and the entity enclosed in a red box is called \"ZAK'S DOG KONA\". Never mention the boxes and their colors. Answer the following question: What is Zak doing and what is Zaks dog kona’s posture?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:37 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:37 Ground Truth: Zak is engaging with the dog playfully and Zaks dog kona’s is lying down.\n",
      "12:37 Prediction: Zak is kneeling on the floor, interacting with his dog, Kona. Kona is lying down, appearing relaxed and attentive.\n",
      "12:37 Result: ✓ CORRECT\n",
      "12:37 \n",
      "================================================================================\n",
      "12:37 Processing [10/54]\n",
      "12:37 Original label: Nikki_Nikkis camper bag\n",
      "12:37 Objects to detect: ['Nikki', 'Nikkis camper bag']\n",
      "12:37 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Nikki_and_Nikkis camper bag/Nikki_Nikkis camper bag_1_positive.png\n",
      "12:37   Mapped 'Nikki' -> 'Nikki-woman'\n",
      "12:37   Mapped 'Nikkis camper bag' -> 'Nikkis camper bag-bag'\n",
      "12:37   Found 2 valid objects: ['Nikki-woman', 'Nikkis camper bag-bag']\n",
      "12:37 Applied sam mask on dino features\n",
      "12:37   Detected 'Nikki-woman' with score 0.639\n",
      "12:37   Detected 'Nikkis camper bag-bag' with score 0.474\n",
      "12:37 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"NIKKI\" and the entity enclosed in a red box is called \"NIKKI'S CAMPER BAG\". Never mention the boxes and their colors. Answer the following question: What is Nikki doing and where is Nikkis camper bag placed ?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:37 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:37 Ground Truth: Nikki is driving a car and Nikkis camper bag is on the back seat.\n",
      "12:37 Prediction: Nikki is driving a vehicle, and her camper bag is placed on the seat next to her.\n",
      "12:37 Result: ✗ INCORRECT\n",
      "12:37 \n",
      "================================================================================\n",
      "12:37 Processing [11/54]\n",
      "12:37 Original label: Nikki_Nikkis camper bag\n",
      "12:37 Objects to detect: ['Nikki', 'Nikkis camper bag']\n",
      "12:37 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Nikki_and_Nikkis camper bag/Nikki_Nikkis camper bag_2_positive.png\n",
      "12:37   Mapped 'Nikki' -> 'Nikki-woman'\n",
      "12:37   Mapped 'Nikkis camper bag' -> 'Nikkis camper bag-bag'\n",
      "12:37   Found 2 valid objects: ['Nikki-woman', 'Nikkis camper bag-bag']\n",
      "12:37 Applied sam mask on dino features\n",
      "12:37   Detected 'Nikki-woman' with score 0.697\n",
      "12:37   Detected 'Nikkis camper bag-bag' with score 0.433\n",
      "12:37 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"NIKKI\" and the entity enclosed in a red box is called \"NIKKI'S CAMPER BAG\". Never mention the boxes and their colors. Answer the following question: Where is Nikki sitting and what is the color of Nikkis camper bag?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:37 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:37 Ground Truth: Nikki is in the back of the car and Nikkis camper bag is blue with gray straps.\n",
      "12:37 Prediction: Nikki is sitting in the back of a vehicle, and Nikki's camper bag is blue.\n",
      "12:37 Result: ✓ CORRECT\n",
      "12:37 \n",
      "================================================================================\n",
      "12:37 Processing [12/54]\n",
      "12:37 Original label: Nikki_Nikkis camper bag\n",
      "12:37 Objects to detect: ['Nikki', 'Nikkis camper bag']\n",
      "12:37 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Nikki_and_Nikkis camper bag/Nikki_Nikkis camper bag_3_positive.png\n",
      "12:37   Mapped 'Nikki' -> 'Nikki-woman'\n",
      "12:37   Mapped 'Nikkis camper bag' -> 'Nikkis camper bag-bag'\n",
      "12:37   Found 2 valid objects: ['Nikki-woman', 'Nikkis camper bag-bag']\n",
      "12:37 Applied sam mask on dino features\n",
      "12:37   Detected 'Nikki-woman' with score 0.658\n",
      "12:37   Detected 'Nikkis camper bag-bag' with score 0.423\n",
      "12:37 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"NIKKI\" and the entity enclosed in a red box is called \"NIKKI'S CAMPER BAG\". Never mention the boxes and their colors. Answer the following question: Where is Nikkis camper bag and what is Nikki doing?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:37 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:37 Ground Truth: Nikkis camper bag is in the car and Nikki is sitting in the backseat.\n",
      "12:37 Prediction: Nikki's camper bag is on the floor of the vehicle. Nikki appears to be reaching towards the bag, possibly organizing or retrieving something from it.\n",
      "12:37 Result: ✗ INCORRECT\n",
      "12:37 \n",
      "================================================================================\n",
      "12:37 Processing [13/54]\n",
      "12:37 Original label: Nikki_Nikkis camper bag\n",
      "12:37 Objects to detect: ['Nikki', 'Nikkis camper bag']\n",
      "12:37 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Nikki_and_Nikkis camper bag/Nikki_Nikkis camper bag_4_positive.png\n",
      "12:37   Mapped 'Nikki' -> 'Nikki-woman'\n",
      "12:37   Mapped 'Nikkis camper bag' -> 'Nikkis camper bag-bag'\n",
      "12:37   Found 2 valid objects: ['Nikki-woman', 'Nikkis camper bag-bag']\n",
      "12:37 Applied sam mask on dino features\n",
      "12:37   Detected 'Nikki-woman' with score 0.726\n",
      "12:37   Detected 'Nikkis camper bag-bag' with score 0.522\n",
      "12:37 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"NIKKI\" and the entity enclosed in a red box is called \"NIKKI'S CAMPER BAG\". Never mention the boxes and their colors. Answer the following question: What is Nikki's expression and where is Nikkis camper bag placed?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:37 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:37 Ground Truth: Nikki looks emotional or teary-eyed and Nikkis camper bag is in the back of the car.\n",
      "12:37 Prediction: Nikki has a neutral expression. Her camper bag is placed in the back of the vehicle.\n",
      "12:37 Result: ✗ INCORRECT\n",
      "12:37 \n",
      "================================================================================\n",
      "12:37 Processing [14/54]\n",
      "12:37 Original label: Nikki_Nikkis camper bag\n",
      "12:37 Objects to detect: ['Nikki', 'Nikkis camper bag']\n",
      "12:37 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Nikki_and_Nikkis camper bag/Nikki_Nikkis camper bag_5_positive.png\n",
      "12:37   Mapped 'Nikki' -> 'Nikki-woman'\n",
      "12:37   Mapped 'Nikkis camper bag' -> 'Nikkis camper bag-bag'\n",
      "12:37   Found 2 valid objects: ['Nikki-woman', 'Nikkis camper bag-bag']\n",
      "12:37 Applied sam mask on dino features\n",
      "12:37   Detected 'Nikki-woman' with score 0.610\n",
      "12:37   Detected 'Nikkis camper bag-bag' with score 0.562\n",
      "12:37 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"NIKKI\" and the entity enclosed in a red box is called \"NIKKI'S CAMPER BAG\". Never mention the boxes and their colors. Answer the following question: Where is Nikki and where is Nikkis camper bag placed?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:38 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:38 Ground Truth: Nikki is at the open car door and Nikkis camper bag is placed on the left side of the back seat on a temporary bed.\n",
      "12:38 Prediction: Nikki is inside the vehicle, and Nikki's camper bag is placed on the seat next to them.\n",
      "12:38 Result: ✗ INCORRECT\n",
      "12:38 \n",
      "================================================================================\n",
      "12:38 Processing [15/54]\n",
      "12:38 Original label: Zak_Zaks dog coffee\n",
      "12:38 Objects to detect: ['Zak', 'Zaks dog coffee']\n",
      "12:38 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Zak_and_Zaks dog coffee/Zak_Zaks dog coffee_1_positive.png\n",
      "12:38   Mapped 'Zak' -> 'Zak-man'\n",
      "12:38   Mapped 'Zaks dog coffee' -> 'Zaks dog coffee-dog'\n",
      "12:38   Found 2 valid objects: ['Zak-man', 'Zaks dog coffee-dog']\n",
      "12:38 Applied sam mask on dino features\n",
      "12:38   Detected 'Zak-man' with score 0.585\n",
      "12:38   Detected 'Zaks dog coffee-dog' with score 0.393\n",
      "12:38 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ZAK\" and the entity enclosed in a red box is called \"ZAK'S DOG COFFEE\". Never mention the boxes and their colors. Answer the following question: What is Zak doing and what is Zaks dog coffee standing near to?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:38 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:38 Ground Truth: Zak is standing in a kitchen, giving a hand signal or command. Zaks dog coffee is standing next to a fridge and a plate on the floor.\n",
      "12:38 Prediction: Zak is gesturing with his hand, possibly giving a command or signal. Zak's dog, Coffee, is standing near a plate on the floor.\n",
      "12:38 Result: ✗ INCORRECT\n",
      "12:38 \n",
      "================================================================================\n",
      "12:38 Processing [16/54]\n",
      "12:38 Original label: Zak_Zaks dog coffee\n",
      "12:38 Objects to detect: ['Zak', 'Zaks dog coffee']\n",
      "12:38 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Zak_and_Zaks dog coffee/Zak_Zaks dog coffee_2_positive.png\n",
      "12:38   Mapped 'Zak' -> 'Zak-man'\n",
      "12:38   Mapped 'Zaks dog coffee' -> 'Zaks dog coffee-dog'\n",
      "12:38   Found 2 valid objects: ['Zak-man', 'Zaks dog coffee-dog']\n",
      "12:38 Applied sam mask on dino features\n",
      "12:38   Detected 'Zak-man' with score 0.781\n",
      "12:38   Detected 'Zaks dog coffee-dog' with score 0.402\n",
      "12:38 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ZAK\" and the entity enclosed in a red box is called \"ZAK'S DOG COFFEE\". Never mention the boxes and their colors. Answer the following question: What is Zak doing and what is Zaks dog coffee doing?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:38 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:38 Ground Truth: Zak is standing in the kitchen with arms crossed and Zaks dog coffee is leaning on the kitchen counter.\n",
      "12:38 Prediction: Zak is standing in the kitchen with his arms crossed, observing the scene. Zak's dog coffee is standing on its hind legs, reaching up towards the counter.\n",
      "12:38 Result: ✗ INCORRECT\n",
      "12:38 \n",
      "================================================================================\n",
      "12:38 Processing [17/54]\n",
      "12:38 Original label: Zak_Zaks dog coffee\n",
      "12:38 Objects to detect: ['Zak', 'Zaks dog coffee']\n",
      "12:38 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Zak_and_Zaks dog coffee/Zak_Zaks dog coffee_3_positive.png\n",
      "12:38   Mapped 'Zak' -> 'Zak-man'\n",
      "12:38   Mapped 'Zaks dog coffee' -> 'Zaks dog coffee-dog'\n",
      "12:38   Found 2 valid objects: ['Zak-man', 'Zaks dog coffee-dog']\n",
      "12:38 Applied sam mask on dino features\n",
      "12:38   Detected 'Zak-man' with score 0.785\n",
      "12:38   Detected 'Zaks dog coffee-dog' with score 0.451\n",
      "12:38 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ZAK\" and the entity enclosed in a red box is called \"ZAK'S DOG COFFEE\". Never mention the boxes and their colors. Answer the following question: What is Zak doing and what is Zaks dog coffee focused on?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:38 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:38 Ground Truth: Zak is kneeling and possibly giving a command and Zaks dog coffee is focused on Zak and the treats on the floor.\n",
      "12:38 Prediction: Zak is kneeling on the floor, and his dog is focused on something on the ground.\n",
      "12:38 Result: ✓ CORRECT\n",
      "12:38 \n",
      "================================================================================\n",
      "12:38 Processing [18/54]\n",
      "12:38 Original label: Zak_Zaks dog coffee\n",
      "12:38 Objects to detect: ['Zak', 'Zaks dog coffee']\n",
      "12:38 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Zak_and_Zaks dog coffee/Zak_Zaks dog coffee_4_positive.png\n",
      "12:38   Mapped 'Zak' -> 'Zak-man'\n",
      "12:38   Mapped 'Zaks dog coffee' -> 'Zaks dog coffee-dog'\n",
      "12:38   Found 2 valid objects: ['Zak-man', 'Zaks dog coffee-dog']\n",
      "12:38 Applied sam mask on dino features\n",
      "12:38   Detected 'Zak-man' with score 0.869\n",
      "12:38   Detected 'Zaks dog coffee-dog' with score 0.502\n",
      "12:38 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ZAK\" and the entity enclosed in a red box is called \"ZAK'S DOG COFFEE\". Never mention the boxes and their colors. Answer the following question: What are Zak and Zaks dog coffee wearing?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:38 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:38 Ground Truth: Zak is wearing a light blue shirt and dark jeans and Zaks dog coffee is wearing a harness with a leash .\n",
      "12:38 Prediction: Zak is wearing a blue shirt and dark pants. Zaks dog coffee is wearing a yellow collar.\n",
      "12:38 Result: ✗ INCORRECT\n",
      "12:38 \n",
      "================================================================================\n",
      "12:38 Processing [19/54]\n",
      "12:38 Original label: Zak_Zaks dog coffee\n",
      "12:38 Objects to detect: ['Zak', 'Zaks dog coffee']\n",
      "12:38 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Zak_and_Zaks dog coffee/Zak_Zaks dog coffee_5_positive.png\n",
      "12:38   Mapped 'Zak' -> 'Zak-man'\n",
      "12:38   Mapped 'Zaks dog coffee' -> 'Zaks dog coffee-dog'\n",
      "12:38   Found 2 valid objects: ['Zak-man', 'Zaks dog coffee-dog']\n",
      "12:38 Applied sam mask on dino features\n",
      "12:38   Detected 'Zak-man' with score 0.800\n",
      "12:38   Detected 'Zaks dog coffee-dog' with score 0.349\n",
      "12:38 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ZAK\" and the entity enclosed in a red box is called \"ZAK'S DOG COFFEE\". Never mention the boxes and their colors. Answer the following question: What is Zak doing and how does Zaks dog coffee appear?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:38 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:38 Ground Truth: Zak is smiling and petting the dog and Zaks dog coffee appears to be happy with its tongue out.\n",
      "12:38 Prediction: Zak is sitting on the grass and smiling. His dog, which is referred to as \"Zak's Dog Coffee,\" appears to be a black dog with its tongue out, looking happy and playful.\n",
      "12:38 Result: ✓ CORRECT\n",
      "12:38 \n",
      "================================================================================\n",
      "12:38 Processing [20/54]\n",
      "12:38 Original label: Sherry_Sherrys road bike\n",
      "12:38 Objects to detect: ['Sherry', 'Sherrys road bike']\n",
      "12:38 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Sherry_and_Sherrys road bike/Sherry_Sherrys road bike_1_positive.png\n",
      "12:38   Mapped 'Sherry' -> 'Sherry-woman'\n",
      "12:38   Mapped 'Sherrys road bike' -> 'Sherrys road bike-bike'\n",
      "12:38   Found 2 valid objects: ['Sherry-woman', 'Sherrys road bike-bike']\n",
      "12:38 Applied sam mask on dino features\n",
      "12:38   Detected 'Sherry-woman' with score 0.444\n",
      "12:38   Detected 'Sherrys road bike-bike' with score 0.216\n",
      "12:38 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"SHERRY\" and the entity enclosed in a red box is called \"SHERRY'S ROAD BIKE\". Never mention the boxes and their colors. Answer the following question: What is under Sherry and what is next to the Sherrys road bike?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:38 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:38 Ground Truth: There is a exercise mat and a foam roller under Sherry and there is a wall and a keyboard next to Sherrys road bike.\n",
      "12:38 Prediction: Sherry is on a blue exercise mat, and next to Sherry's road bike is a piano.\n",
      "12:38 Result: ✗ INCORRECT\n",
      "12:38 \n",
      "================================================================================\n",
      "12:38 Processing [21/54]\n",
      "12:38 Original label: Sherry_Sherrys road bike\n",
      "12:38 Objects to detect: ['Sherry', 'Sherrys road bike']\n",
      "12:38 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Sherry_and_Sherrys road bike/Sherry_Sherrys road bike_2_positive.png\n",
      "12:38   Mapped 'Sherry' -> 'Sherry-woman'\n",
      "12:38   Mapped 'Sherrys road bike' -> 'Sherrys road bike-bike'\n",
      "12:38   Found 2 valid objects: ['Sherry-woman', 'Sherrys road bike-bike']\n",
      "12:38 Applied sam mask on dino features\n",
      "12:38   Detected 'Sherry-woman' with score 0.562\n",
      "12:38   Detected 'Sherrys road bike-bike' with score 0.233\n",
      "12:38 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"SHERRY\" and the entity enclosed in a red box is called \"SHERRY'S ROAD BIKE\". Never mention the boxes and their colors. Answer the following question: What is Sherry wearing and where is Sherrys road bike placed?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:38 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:38 Ground Truth: Sherry is wearing a black and gray cycling kit and Sherrys road bike is placed next to a wall near the door.\n",
      "12:38 Prediction: Sherry is wearing a black and white shirt and black shorts. Sherry's road bike is placed against the wall near the door.\n",
      "12:38 Result: ✓ CORRECT\n",
      "12:38 \n",
      "================================================================================\n",
      "12:38 Processing [22/54]\n",
      "12:38 Original label: Sherry_Sherrys road bike\n",
      "12:38 Objects to detect: ['Sherry', 'Sherrys road bike']\n",
      "12:38 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Sherry_and_Sherrys road bike/Sherry_Sherrys road bike_3_positive.png\n",
      "12:38   Mapped 'Sherry' -> 'Sherry-woman'\n",
      "12:38   Mapped 'Sherrys road bike' -> 'Sherrys road bike-bike'\n",
      "12:38   Found 2 valid objects: ['Sherry-woman', 'Sherrys road bike-bike']\n",
      "12:38 Applied sam mask on dino features\n",
      "12:38   Detected 'Sherry-woman' with score 0.438\n",
      "12:38   Detected 'Sherrys road bike-bike' with score 0.243\n",
      "12:38 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"SHERRY\" and the entity enclosed in a red box is called \"SHERRY'S ROAD BIKE\". Never mention the boxes and their colors. Answer the following question: what is Sherry carrying and What is the position of Sherrys road bike?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:38 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:38 Ground Truth: Sherry is carrying a laptop and a cup and Sherrys road bike is mounted upside down.\n",
      "12:38 Prediction: Sherry is carrying a laptop. Sherry's road bike is positioned against the wall.\n",
      "12:38 Result: ✗ INCORRECT\n",
      "12:38 \n",
      "================================================================================\n",
      "12:38 Processing [23/54]\n",
      "12:38 Original label: Sherry_Sherrys road bike\n",
      "12:38 Objects to detect: ['Sherry', 'Sherrys road bike']\n",
      "12:38 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Sherry_and_Sherrys road bike/Sherry_Sherrys road bike_4_positive.png\n",
      "12:38   Mapped 'Sherry' -> 'Sherry-woman'\n",
      "12:38   Mapped 'Sherrys road bike' -> 'Sherrys road bike-bike'\n",
      "12:38   Found 2 valid objects: ['Sherry-woman', 'Sherrys road bike-bike']\n",
      "12:38 Applied sam mask on dino features\n",
      "12:38   Detected 'Sherry-woman' with score 0.446\n",
      "12:38   Detected 'Sherrys road bike-bike' with score 0.327\n",
      "12:38 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"SHERRY\" and the entity enclosed in a red box is called \"SHERRY'S ROAD BIKE\". Never mention the boxes and their colors. Answer the following question: Which one is Sherry and which one is Sherrys road bike?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:38 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:38 Ground Truth: Sherry is the woman and Sherrys road bike is the one right behind her.\n",
      "12:38 Prediction: The person in the image is Sherry, and the bicycle in the background is Sherry's road bike.\n",
      "12:38 Result: ✓ CORRECT\n",
      "12:38 \n",
      "================================================================================\n",
      "12:38 Processing [24/54]\n",
      "12:38 Original label: Sherry_Sherrys road bike\n",
      "12:38 Objects to detect: ['Sherry', 'Sherrys road bike']\n",
      "12:38 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Sherry_and_Sherrys road bike/Sherry_Sherrys road bike_5_positive.png\n",
      "12:38   Mapped 'Sherry' -> 'Sherry-woman'\n",
      "12:38   Mapped 'Sherrys road bike' -> 'Sherrys road bike-bike'\n",
      "12:38   Found 2 valid objects: ['Sherry-woman', 'Sherrys road bike-bike']\n",
      "12:38 Applied sam mask on dino features\n",
      "12:38   Detected 'Sherry-woman' with score 0.555\n",
      "12:38   Detected 'Sherrys road bike-bike' with score 0.194\n",
      "12:38 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"SHERRY\" and the entity enclosed in a red box is called \"SHERRY'S ROAD BIKE\". Never mention the boxes and their colors. Answer the following question: What is Sherry wearing and which one is Sherrys road bike?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:38 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:38 Ground Truth: Sherry is wearing a black and orange cycling kit and a blue helmet and Sherrys road bike is the one in front.\n",
      "12:38 Prediction: Sherry is wearing a black and orange outfit. Sherry's road bike is the one she is riding in the image.\n",
      "12:38 Result: ✓ CORRECT\n",
      "12:38 \n",
      "================================================================================\n",
      "12:38 Processing [25/54]\n",
      "12:38 Original label: Casey_Caseys son\n",
      "12:38 Objects to detect: ['Casey', 'Caseys son']\n",
      "12:38 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Casey_and_Caseys son/Casey_Caseys son_1_positive.png\n",
      "12:38   Mapped 'Casey' -> 'Casey-man'\n",
      "12:38   Mapped 'Caseys son' -> 'Caseys son-man'\n",
      "12:38   Found 2 valid objects: ['Casey-man', 'Caseys son-man']\n",
      "12:38 Applied sam mask on dino features\n",
      "12:38   Detected 'Casey-man' with score 0.224\n",
      "12:38   Detected 'Caseys son-man' with score 0.533\n",
      "12:38 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"CASEY\" and the entity enclosed in a red box is called \"CASEY'S SON\". Never mention the boxes and their colors. Answer the following question: What are Casey and Caseys son wearing?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:38 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:38 Ground Truth: Casey is wearing a white shirt and sunglasses. Caseys son is wearing a hoodie with starts and stripes that resembles the American flag.\n",
      "12:38 Prediction: Casey is wearing a white long-sleeve shirt and sunglasses, while Casey's son is wearing a hoodie with a star pattern.\n",
      "12:38 Result: ✓ CORRECT\n",
      "12:38 \n",
      "================================================================================\n",
      "12:38 Processing [26/54]\n",
      "12:38 Original label: Casey_Caseys son\n",
      "12:38 Objects to detect: ['Casey', 'Caseys son']\n",
      "12:38 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Casey_and_Caseys son/Casey_Caseys son_2_positive.png\n",
      "12:38   Mapped 'Casey' -> 'Casey-man'\n",
      "12:38   Mapped 'Caseys son' -> 'Caseys son-man'\n",
      "12:38   Found 2 valid objects: ['Casey-man', 'Caseys son-man']\n",
      "12:38 Applied sam mask on dino features\n",
      "12:38   Detected 'Casey-man' with score 0.319\n",
      "12:38   Detected 'Caseys son-man' with score 0.587\n",
      "12:38 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"CASEY\" and the entity enclosed in a red box is called \"CASEY'S SON\". Never mention the boxes and their colors. Answer the following question: What is Casey wearing and what is Caseys son doing?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:38 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:38 Ground Truth: Casey is wearing a red shirt, sunglasses, and a backwards cap and Caseys son is driving the car.\n",
      "12:38 Prediction: Casey is wearing a red shirt and a red cap. Casey's son is looking out the window.\n",
      "12:38 Result: ✗ INCORRECT\n",
      "12:38 \n",
      "================================================================================\n",
      "12:38 Processing [27/54]\n",
      "12:38 Original label: Casey_Caseys son\n",
      "12:38 Objects to detect: ['Casey', 'Caseys son']\n",
      "12:38 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Casey_and_Caseys son/Casey_Caseys son_3_positive.png\n",
      "12:38   Mapped 'Casey' -> 'Casey-man'\n",
      "12:38   Mapped 'Caseys son' -> 'Caseys son-man'\n",
      "12:38   Found 2 valid objects: ['Casey-man', 'Caseys son-man']\n",
      "12:38 Applied sam mask on dino features\n",
      "12:38   Detected 'Casey-man' with score 0.321\n",
      "12:38   Detected 'Caseys son-man' with score 0.585\n",
      "12:38 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"CASEY\" and the entity enclosed in a red box is called \"CASEY'S SON\". Never mention the boxes and their colors. Answer the following question: What direction are Casey and Caseys son looking at?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:38 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:38 Ground Truth: Casey is looking towards the camera while Caseys son is looking straight ahead at the road.\n",
      "12:38 Prediction: Casey is looking forward, while Casey's son is looking to the side.\n",
      "12:38 Result: ✗ INCORRECT\n",
      "12:38 \n",
      "================================================================================\n",
      "12:38 Processing [28/54]\n",
      "12:38 Original label: Casey_Caseys son\n",
      "12:38 Objects to detect: ['Casey', 'Caseys son']\n",
      "12:38 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Casey_and_Caseys son/Casey_Caseys son_4_positive.png\n",
      "12:38   Mapped 'Casey' -> 'Casey-man'\n",
      "12:38   Mapped 'Caseys son' -> 'Caseys son-man'\n",
      "12:38   Found 2 valid objects: ['Casey-man', 'Caseys son-man']\n",
      "12:38 Applied sam mask on dino features\n",
      "12:38   Detected 'Casey-man' with score 0.228\n",
      "12:38   Detected 'Caseys son-man' with score 0.524\n",
      "12:38 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"CASEY\" and the entity enclosed in a red box is called \"CASEY'S SON\". Never mention the boxes and their colors. Answer the following question: What accessory does Casey have and what is Caseys son holding?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:38 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:38 Ground Truth: Casey has Sunglasses and Caseys son is holding a passport.\n",
      "12:38 Prediction: Casey is wearing sunglasses, and Casey's son is holding a book.\n",
      "12:38 Result: ✗ INCORRECT\n",
      "12:38 \n",
      "================================================================================\n",
      "12:38 Processing [29/54]\n",
      "12:38 Original label: Casey_Caseys son\n",
      "12:38 Objects to detect: ['Casey', 'Caseys son']\n",
      "12:38 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Casey_and_Caseys son/Casey_Caseys son_5_positive.png\n",
      "12:38   Mapped 'Casey' -> 'Casey-man'\n",
      "12:38   Mapped 'Caseys son' -> 'Caseys son-man'\n",
      "12:38   Found 2 valid objects: ['Casey-man', 'Caseys son-man']\n",
      "12:38 Applied sam mask on dino features\n",
      "12:38   Detected 'Casey-man' with score 0.206\n",
      "12:38   Detected 'Caseys son-man' with score 0.513\n",
      "12:38 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"CASEY\" and the entity enclosed in a red box is called \"CASEY'S SON\". Never mention the boxes and their colors. Answer the following question: What are Casey and Caseys son doing?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:38 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:38 Ground Truth: Casey is gesturing with his hand while Caseys son is looking at something off to the side while walking in an airport.\n",
      "12:38 Prediction: Casey and Casey's son appear to be standing outdoors, possibly on a street or in a parking area. They seem to be engaged in a conversation or looking at something together, as they are both facing upwards.\n",
      "12:38 Result: ✗ INCORRECT\n",
      "12:38 \n",
      "================================================================================\n",
      "12:38 Processing [30/54]\n",
      "12:38 Original label: Blippi_Blippis shoes\n",
      "12:38 Objects to detect: ['Blippi', 'Blippis shoes']\n",
      "12:38 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Blippi_and_Blippis shoes/Blippi_Blippis shoes_1_positive.png\n",
      "12:38   Mapped 'Blippi' -> 'Blippi-man'\n",
      "12:38   Mapped 'Blippis shoes' -> 'Blippis shoes-shoes'\n",
      "12:38   Found 2 valid objects: ['Blippi-man', 'Blippis shoes-shoes']\n",
      "12:39 Applied sam mask on dino features\n",
      "12:39   Detected 'Blippi-man' with score 0.332\n",
      "12:39   Detected 'Blippis shoes-shoes' with score 0.456\n",
      "12:39 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"BLIPPI\" and the entity enclosed in a red box is called \"BLIPPI'S SHOES\". Never mention the boxes and their colors. Answer the following question: Where is Blippi and What color are Blippis shoes ?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:39 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:39 Ground Truth: Blippi seems to be walking on a treadmil in a gym and Blippis shoes are primarily blue with orange accents.\n",
      "12:39 Prediction: Blippi is on a treadmill. Blippi's shoes are blue.\n",
      "12:39 Result: ✓ CORRECT\n",
      "12:39 \n",
      "================================================================================\n",
      "12:39 Processing [31/54]\n",
      "12:39 Original label: Blippi_Blippis shoes\n",
      "12:39 Objects to detect: ['Blippi', 'Blippis shoes']\n",
      "12:39 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Blippi_and_Blippis shoes/Blippi_Blippis shoes_2_positive.png\n",
      "12:39   Mapped 'Blippi' -> 'Blippi-man'\n",
      "12:39   Mapped 'Blippis shoes' -> 'Blippis shoes-shoes'\n",
      "12:39   Found 2 valid objects: ['Blippi-man', 'Blippis shoes-shoes']\n",
      "12:39 Applied sam mask on dino features\n",
      "12:39   Detected 'Blippi-man' with score 0.462\n",
      "12:39   Detected 'Blippis shoes-shoes' with score 0.736\n",
      "12:39 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"BLIPPI\" and the entity enclosed in a red box is called \"BLIPPI'S SHOES\". Never mention the boxes and their colors. Answer the following question: Which one is Blippi and whibe one is Blippis shoes ?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:39 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:39 Ground Truth: Blippi is the man wearing blue and orange outfit and Blippis shoes are the blue and orange sneakers he is wearing.\n",
      "12:39 Prediction: The entity called \"BLIPPI\" is the person wearing an orange hat and blue shirt. The entity called \"BLIPPI'S SHOES\" is the yellow bicycle.\n",
      "12:39 Result: ✗ INCORRECT\n",
      "12:39 \n",
      "================================================================================\n",
      "12:39 Processing [32/54]\n",
      "12:39 Original label: Blippi_Blippis shoes\n",
      "12:39 Objects to detect: ['Blippi', 'Blippis shoes']\n",
      "12:39 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Blippi_and_Blippis shoes/Blippi_Blippis shoes_3_positive.png\n",
      "12:39   Mapped 'Blippi' -> 'Blippi-man'\n",
      "12:39   Mapped 'Blippis shoes' -> 'Blippis shoes-shoes'\n",
      "12:39   Found 2 valid objects: ['Blippi-man', 'Blippis shoes-shoes']\n",
      "12:39 Applied sam mask on dino features\n",
      "12:39   Detected 'Blippi-man' with score 0.356\n",
      "12:39   Detected 'Blippis shoes-shoes' with score 0.469\n",
      "12:39 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"BLIPPI\" and the entity enclosed in a red box is called \"BLIPPI'S SHOES\". Never mention the boxes and their colors. Answer the following question: Is Blippi weraing Blippis shoes?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:39 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:39 Ground Truth: No, Blippi is wearing brown roller skates while Blippis shoes are placed beside him.\n",
      "12:39 Prediction: Yes, Blippi is wearing Blippi's shoes.\n",
      "12:39 Result: ✗ INCORRECT\n",
      "12:39 \n",
      "================================================================================\n",
      "12:39 Processing [33/54]\n",
      "12:39 Original label: Blippi_Blippis shoes\n",
      "12:39 Objects to detect: ['Blippi', 'Blippis shoes']\n",
      "12:39 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Blippi_and_Blippis shoes/Blippi_Blippis shoes_4_positive.png\n",
      "12:39   Mapped 'Blippi' -> 'Blippi-man'\n",
      "12:39   Mapped 'Blippis shoes' -> 'Blippis shoes-shoes'\n",
      "12:39   Found 2 valid objects: ['Blippi-man', 'Blippis shoes-shoes']\n",
      "12:39 Applied sam mask on dino features\n",
      "12:39   Detected 'Blippi-man' with score 0.437\n",
      "12:39   Detected 'Blippis shoes-shoes' with score 0.440\n",
      "12:39 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"BLIPPI\" and the entity enclosed in a red box is called \"BLIPPI'S SHOES\". Never mention the boxes and their colors. Answer the following question: Do Blippis shoes match the color of Blippi's outfit?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:39 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:39 Ground Truth: Yes, Blippi is wearing a colorful blue and orange outfit matching Blippis shoes.\n",
      "12:39 Prediction: Yes, Blippi's shoes match the color of his outfit. The shoes are bright and colorful, complementing the vibrant attire.\n",
      "12:39 Result: ✓ CORRECT\n",
      "12:39 \n",
      "================================================================================\n",
      "12:39 Processing [34/54]\n",
      "12:39 Original label: Blippi_Blippis shoes\n",
      "12:39 Objects to detect: ['Blippi', 'Blippis shoes']\n",
      "12:39 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Blippi_and_Blippis shoes/Blippi_Blippis shoes_5_positive.png\n",
      "12:39   Mapped 'Blippi' -> 'Blippi-man'\n",
      "12:39   Mapped 'Blippis shoes' -> 'Blippis shoes-shoes'\n",
      "12:39   Found 2 valid objects: ['Blippi-man', 'Blippis shoes-shoes']\n",
      "12:39 Applied sam mask on dino features\n",
      "12:39   Detected 'Blippi-man' with score 0.344\n",
      "12:39   Detected 'Blippis shoes-shoes' with score 0.395\n",
      "12:39 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"BLIPPI\" and the entity enclosed in a red box is called \"BLIPPI'S SHOES\". Never mention the boxes and their colors. Answer the following question: What is Blippi doing and what color are Blippis shoes ?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:39 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:39 Ground Truth: Blippi is looking to his side in a helmet shop. Blippis shoes are blue and orange.\n",
      "12:39 Prediction: Blippi is standing in a store, and his shoes are orange.\n",
      "12:39 Result: ✗ INCORRECT\n",
      "12:39 \n",
      "================================================================================\n",
      "12:39 Processing [35/54]\n",
      "12:39 Original label: Alex_Alexs everyday bag\n",
      "12:39 Objects to detect: ['Alex', 'Alexs everyday bag']\n",
      "12:39 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Alex_and_Alexs everyday bag/Alex_Alexs everyday bag_1_positive.png\n",
      "12:39   Mapped 'Alex' -> 'Alex-woman'\n",
      "12:39   Mapped 'Alexs everyday bag' -> 'Alexs everyday bag-bag'\n",
      "12:39   Found 2 valid objects: ['Alex-woman', 'Alexs everyday bag-bag']\n",
      "12:39 Applied sam mask on dino features\n",
      "12:39   Detected 'Alex-woman' with score 0.672\n",
      "12:39   Detected 'Alexs everyday bag-bag' with score 0.305\n",
      "12:39 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ALEX\" and the entity enclosed in a red box is called \"ALEX'S EVERYDAY BAG\". Never mention the boxes and their colors. Answer the following question: How is Alex styled and What is Alexs everyday bag ?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:39 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:39 Ground Truth: Alex is wearing a velvet pink top and minimal jewelry. Alexs everyday bag is a Louis Vuitton handbag.\n",
      "12:39 Prediction: Alex is styled in a shiny, pink, short-sleeved top. Alex's everyday bag is a black handbag with a structured design.\n",
      "12:39 Result: ✗ INCORRECT\n",
      "12:39 \n",
      "================================================================================\n",
      "12:39 Processing [36/54]\n",
      "12:39 Original label: Alex_Alexs everyday bag\n",
      "12:39 Objects to detect: ['Alex', 'Alexs everyday bag']\n",
      "12:39 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Alex_and_Alexs everyday bag/Alex_Alexs everyday bag_2_positive.png\n",
      "12:39   Mapped 'Alex' -> 'Alex-woman'\n",
      "12:39   Mapped 'Alexs everyday bag' -> 'Alexs everyday bag-bag'\n",
      "12:39   Found 2 valid objects: ['Alex-woman', 'Alexs everyday bag-bag']\n",
      "12:39 Applied sam mask on dino features\n",
      "12:39   Detected 'Alex-woman' with score 0.743\n",
      "12:39   Detected 'Alexs everyday bag-bag' with score 0.265\n",
      "12:39 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ALEX\" and the entity enclosed in a red box is called \"ALEX'S EVERYDAY BAG\". Never mention the boxes and their colors. Answer the following question: What is Alex doing and What is inside Alexs everyday bag ?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:39 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:39 Ground Truth: Alex is holding and looking inside Alexs everyday bag. There is a black object inside Alexs everyday bag.\n",
      "12:39 Prediction: Alex is holding and examining their everyday bag. Inside the bag, there appears to be a small container or pouch.\n",
      "12:39 Result: ✓ CORRECT\n",
      "12:39 \n",
      "================================================================================\n",
      "12:39 Processing [37/54]\n",
      "12:39 Original label: Alex_Alexs everyday bag\n",
      "12:39 Objects to detect: ['Alex', 'Alexs everyday bag']\n",
      "12:39 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Alex_and_Alexs everyday bag/Alex_Alexs everyday bag_3_positive.png\n",
      "12:39   Mapped 'Alex' -> 'Alex-woman'\n",
      "12:39   Mapped 'Alexs everyday bag' -> 'Alexs everyday bag-bag'\n",
      "12:39   Found 2 valid objects: ['Alex-woman', 'Alexs everyday bag-bag']\n",
      "12:39 Applied sam mask on dino features\n",
      "12:39   Detected 'Alex-woman' with score 0.648\n",
      "12:39   Detected 'Alexs everyday bag-bag' with score 0.282\n",
      "12:39 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ALEX\" and the entity enclosed in a red box is called \"ALEX'S EVERYDAY BAG\". Never mention the boxes and their colors. Answer the following question: What is Alex showing and What kind of hardware does Alexs everyday bag have?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:39 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:39 Ground Truth: Alex is showing how to hold Alexs everyday bag by its strap. Alexs everyday bag has gold hardware.\n",
      "12:39 Prediction: Alex is showing a bag. Alex's everyday bag has gold hardware.\n",
      "12:39 Result: ✓ CORRECT\n",
      "12:39 \n",
      "================================================================================\n",
      "12:39 Processing [38/54]\n",
      "12:39 Original label: Alex_Alexs everyday bag\n",
      "12:39 Objects to detect: ['Alex', 'Alexs everyday bag']\n",
      "12:39 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Alex_and_Alexs everyday bag/Alex_Alexs everyday bag_4_positive.png\n",
      "12:39   Mapped 'Alex' -> 'Alex-woman'\n",
      "12:39   Mapped 'Alexs everyday bag' -> 'Alexs everyday bag-bag'\n",
      "12:39   Found 2 valid objects: ['Alex-woman', 'Alexs everyday bag-bag']\n",
      "12:39 Applied sam mask on dino features\n",
      "12:39   Detected 'Alex-woman' with score 0.698\n",
      "12:39   Detected 'Alexs everyday bag-bag' with score 0.266\n",
      "12:39 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ALEX\" and the entity enclosed in a red box is called \"ALEX'S EVERYDAY BAG\". Never mention the boxes and their colors. Answer the following question: Where is Alex and what was taken out of Alexs everyday bag?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:39 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:39 Ground Truth: Alex seems to be in a bedroom and a camera was taken out of Alexs everyday bag.\n",
      "12:39 Prediction: Alex is in a room, possibly a bedroom, with a decorative wall and some string lights in the background. A camera was taken out of Alex's everyday bag.\n",
      "12:39 Result: ✓ CORRECT\n",
      "12:39 \n",
      "================================================================================\n",
      "12:39 Processing [39/54]\n",
      "12:39 Original label: Alex_Alexs everyday bag\n",
      "12:39 Objects to detect: ['Alex', 'Alexs everyday bag']\n",
      "12:39 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Alex_and_Alexs everyday bag/Alex_Alexs everyday bag_5_positive.png\n",
      "12:39   Mapped 'Alex' -> 'Alex-woman'\n",
      "12:39   Mapped 'Alexs everyday bag' -> 'Alexs everyday bag-bag'\n",
      "12:39   Found 2 valid objects: ['Alex-woman', 'Alexs everyday bag-bag']\n",
      "12:39 Applied sam mask on dino features\n",
      "12:39   Detected 'Alex-woman' with score 0.739\n",
      "12:39   Detected 'Alexs everyday bag-bag' with score 0.269\n",
      "12:39 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ALEX\" and the entity enclosed in a red box is called \"ALEX'S EVERYDAY BAG\". Never mention the boxes and their colors. Answer the following question: What is Alex doing and which one is Alexs everyday bag?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:39 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:39 Ground Truth: Alex is holding up and possibly comparing two bags. The smaller bag on the right is Alexs everyday bag.\n",
      "12:39 Prediction: Alex is holding two bags. Alex's everyday bag is the one on the right.\n",
      "12:39 Result: ✓ CORRECT\n",
      "12:39 \n",
      "================================================================================\n",
      "12:39 Processing [40/54]\n",
      "12:39 Original label: Alex_Alexs hat\n",
      "12:39 Objects to detect: ['Alex', 'Alexs hat']\n",
      "12:39 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Alex_and_Alexs hat/Alex_Alexs hat_1_positive.png\n",
      "12:39   Mapped 'Alex' -> 'Alex-woman'\n",
      "12:39   Mapped 'Alexs hat' -> 'Alexs hat-hat'\n",
      "12:39   Found 2 valid objects: ['Alex-woman', 'Alexs hat-hat']\n",
      "12:39 Applied sam mask on dino features\n",
      "12:39   Detected 'Alex-woman' with score 0.280\n",
      "12:39   Detected 'Alexs hat-hat' with score 0.496\n",
      "12:39 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ALEX\" and the entity enclosed in a red box is called \"ALEX'S HAT\". Never mention the boxes and their colors. Answer the following question: Where is Alex and Where is Alexs hat located ?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:39 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:39 Ground Truth: Alex is sitting inside a room and Alexs hat is hanging on the wall behind Alex\n",
      "12:39 Prediction: Alex is in a room, and Alex's hat is on the wall behind them.\n",
      "12:39 Result: ✓ CORRECT\n",
      "12:39 \n",
      "================================================================================\n",
      "12:39 Processing [41/54]\n",
      "12:39 Original label: Alex_Alexs hat\n",
      "12:39 Objects to detect: ['Alex', 'Alexs hat']\n",
      "12:39 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Alex_and_Alexs hat/Alex_Alexs hat_2_positive.png\n",
      "12:39   Mapped 'Alex' -> 'Alex-woman'\n",
      "12:39   Mapped 'Alexs hat' -> 'Alexs hat-hat'\n",
      "12:39   Found 2 valid objects: ['Alex-woman', 'Alexs hat-hat']\n",
      "12:39 Applied sam mask on dino features\n",
      "12:39   Detected 'Alex-woman' with score 0.265\n",
      "12:39   Detected 'Alexs hat-hat' with score 0.498\n",
      "12:39 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ALEX\" and the entity enclosed in a red box is called \"ALEX'S HAT\". Never mention the boxes and their colors. Answer the following question: What is Alex wearing and is Alexs hat being worn ?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:39 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:39 Ground Truth: Alex is wearing a light white shirt. No, Alexs hat is hanging on the wall.\n",
      "12:39 Prediction: Alex is wearing a light-colored shirt. Alex's hat is not being worn; it is placed on a wall.\n",
      "12:39 Result: ✓ CORRECT\n",
      "12:39 \n",
      "================================================================================\n",
      "12:39 Processing [42/54]\n",
      "12:39 Original label: Alex_Alexs hat\n",
      "12:39 Objects to detect: ['Alex', 'Alexs hat']\n",
      "12:39 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Alex_and_Alexs hat/Alex_Alexs hat_3_positive.png\n",
      "12:39   Mapped 'Alex' -> 'Alex-woman'\n",
      "12:39   Mapped 'Alexs hat' -> 'Alexs hat-hat'\n",
      "12:39   Found 2 valid objects: ['Alex-woman', 'Alexs hat-hat']\n",
      "12:39 Applied sam mask on dino features\n",
      "12:39   Detected 'Alex-woman' with score 0.271\n",
      "12:39   Detected 'Alexs hat-hat' with score 0.510\n",
      "12:39 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ALEX\" and the entity enclosed in a red box is called \"ALEX'S HAT\". Never mention the boxes and their colors. Answer the following question: Is Alex interacting with Alexs hat?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:39 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:39 Ground Truth: No, Alex seems to be posing with her dress while Alexs hat is hanging on the wall.\n",
      "12:39 Prediction: No, Alex is not interacting with Alex's hat.\n",
      "12:39 Result: ✓ CORRECT\n",
      "12:39 \n",
      "================================================================================\n",
      "12:39 Processing [43/54]\n",
      "12:39 Original label: Alex_Alexs hat\n",
      "12:39 Objects to detect: ['Alex', 'Alexs hat']\n",
      "12:39 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Alex_and_Alexs hat/Alex_Alexs hat_4_positive.png\n",
      "12:39   Mapped 'Alex' -> 'Alex-woman'\n",
      "12:39   Mapped 'Alexs hat' -> 'Alexs hat-hat'\n",
      "12:39   Found 2 valid objects: ['Alex-woman', 'Alexs hat-hat']\n",
      "12:39 Applied sam mask on dino features\n",
      "12:39   Detected 'Alex-woman' with score 0.277\n",
      "12:39   Detected 'Alexs hat-hat' with score 0.487\n",
      "12:39 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ALEX\" and the entity enclosed in a red box is called \"ALEX'S HAT\". Never mention the boxes and their colors. Answer the following question: What is Alex doing and what is Alexs hat made off?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:39 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:39 Ground Truth: Alex seems to be talking to the camera while facing a mirror. The hat is made of straw.\n",
      "12:39 Prediction: Alex is standing in front of a mirror, possibly adjusting their outfit or preparing for an event. Alex's hat appears to be made of straw.\n",
      "12:39 Result: ✓ CORRECT\n",
      "12:39 \n",
      "================================================================================\n",
      "12:39 Processing [44/54]\n",
      "12:39 Original label: Alex_Alexs hat\n",
      "12:39 Objects to detect: ['Alex', 'Alexs hat']\n",
      "12:39 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Alex_and_Alexs hat/Alex_Alexs hat_5_positive.png\n",
      "12:39   Mapped 'Alex' -> 'Alex-woman'\n",
      "12:39   Mapped 'Alexs hat' -> 'Alexs hat-hat'\n",
      "12:39   Found 2 valid objects: ['Alex-woman', 'Alexs hat-hat']\n",
      "12:39 Applied sam mask on dino features\n",
      "12:40   Detected 'Alex-woman' with score 0.332\n",
      "12:40   Detected 'Alexs hat-hat' with score 0.431\n",
      "12:40 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"ALEX\" and the entity enclosed in a red box is called \"ALEX'S HAT\". Never mention the boxes and their colors. Answer the following question: What is Alex wearing and Where is Alexs hat positioned in relation to Alex?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:40 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:40 Ground Truth: Alex is wearing a green dress and Alexs hat is placed behind her head on the wall.\n",
      "12:40 Prediction: Alex is wearing a light-colored, long-sleeved top. Alex's hat is positioned on their head.\n",
      "12:40 Result: ✗ INCORRECT\n",
      "12:40 \n",
      "================================================================================\n",
      "12:40 Processing [45/54]\n",
      "12:40 Original label: Nikki_Nikkis car\n",
      "12:40 Objects to detect: ['Nikki', 'Nikkis car']\n",
      "12:40 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Nikki_and_Nikkis car/Nikki_Nikkis car_1_positive.png\n",
      "12:40   Mapped 'Nikki' -> 'Nikki-woman'\n",
      "12:40   Mapped 'Nikkis car' -> 'Nikkis car-car'\n",
      "12:40   Found 2 valid objects: ['Nikki-woman', 'Nikkis car-car']\n",
      "12:40 Applied sam mask on dino features\n",
      "12:40   Detected 'Nikki-woman' with score 0.789\n",
      "12:40   Detected 'Nikkis car-car' with score 0.532\n",
      "12:40 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"NIKKI\" and the entity enclosed in a red box is called \"NIKKI'S CAR\". Never mention the boxes and their colors. Answer the following question: What is Nikki wearing and what color Nikkis car?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:40 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:40 Ground Truth: Nikki is wearing a black tank top and Nikkis car is silver or light green.\n",
      "12:40 Prediction: Nikki is wearing a black tank top and a red bracelet. Nikki's car is light green.\n",
      "12:40 Result: ✓ CORRECT\n",
      "12:40 \n",
      "================================================================================\n",
      "12:40 Processing [46/54]\n",
      "12:40 Original label: Nikki_Nikkis car\n",
      "12:40 Objects to detect: ['Nikki', 'Nikkis car']\n",
      "12:40 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Nikki_and_Nikkis car/Nikki_Nikkis car_2_positive.png\n",
      "12:40   Mapped 'Nikki' -> 'Nikki-woman'\n",
      "12:40   Mapped 'Nikkis car' -> 'Nikkis car-car'\n",
      "12:40   Found 2 valid objects: ['Nikki-woman', 'Nikkis car-car']\n",
      "12:40 Applied sam mask on dino features\n",
      "12:40   Detected 'Nikki-woman' with score 0.558\n",
      "12:40   Detected 'Nikkis car-car' with score 0.398\n",
      "12:40 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"NIKKI\" and the entity enclosed in a red box is called \"NIKKI'S CAR\". Never mention the boxes and their colors. Answer the following question: What is Nikki lifting and which one is Nikkis car?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:40 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:40 Ground Truth: Nikki is lifting a larg suitcase or cargo box and Nikkis car is the light green vehicle behind her.\n",
      "12:40 Prediction: Nikki is lifting a kayak. The silver car behind her is Nikki's car.\n",
      "12:40 Result: ✗ INCORRECT\n",
      "12:40 \n",
      "================================================================================\n",
      "12:40 Processing [47/54]\n",
      "12:40 Original label: Nikki_Nikkis car\n",
      "12:40 Objects to detect: ['Nikki', 'Nikkis car']\n",
      "12:40 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Nikki_and_Nikkis car/Nikki_Nikkis car_3_positive.png\n",
      "12:40   Mapped 'Nikki' -> 'Nikki-woman'\n",
      "12:40   Mapped 'Nikkis car' -> 'Nikkis car-car'\n",
      "12:40   Found 2 valid objects: ['Nikki-woman', 'Nikkis car-car']\n",
      "12:40 Applied sam mask on dino features\n",
      "12:40   Detected 'Nikki-woman' with score 0.691\n",
      "12:40   Detected 'Nikkis car-car' with score 0.585\n",
      "12:40 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"NIKKI\" and the entity enclosed in a red box is called \"NIKKI'S CAR\". Never mention the boxes and their colors. Answer the following question: What does Nikki appear to be doing and what is on top of Nikkis car?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:40 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:40 Ground Truth: Nikki is standing next to Nikkis car and seems to be talking to a man and there is a black rooftop cargo box on top of Nikkis car.\n",
      "12:40 Prediction: Nikki appears to be talking and gesturing with her hands. On top of Nikki's car, there is a surfboard.\n",
      "12:40 Result: ✗ INCORRECT\n",
      "12:40 \n",
      "================================================================================\n",
      "12:40 Processing [48/54]\n",
      "12:40 Original label: Nikki_Nikkis car\n",
      "12:40 Objects to detect: ['Nikki', 'Nikkis car']\n",
      "12:40 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Nikki_and_Nikkis car/Nikki_Nikkis car_4_positive.png\n",
      "12:40   Mapped 'Nikki' -> 'Nikki-woman'\n",
      "12:40   Mapped 'Nikkis car' -> 'Nikkis car-car'\n",
      "12:40   Found 2 valid objects: ['Nikki-woman', 'Nikkis car-car']\n",
      "12:40 Applied sam mask on dino features\n",
      "12:40   Detected 'Nikki-woman' with score 0.763\n",
      "12:40   Detected 'Nikkis car-car' with score 0.613\n",
      "12:40 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"NIKKI\" and the entity enclosed in a red box is called \"NIKKI'S CAR\". Never mention the boxes and their colors. Answer the following question: What is Nikki doing and where is Nikkis car located?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:40 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:40 Ground Truth: Nikki is smiling at the camera and Nikkis car is in a garage or repair shop.\n",
      "12:40 Prediction: Nikki is sitting in a garage, and Nikki's car is parked nearby.\n",
      "12:40 Result: ✗ INCORRECT\n",
      "12:40 \n",
      "================================================================================\n",
      "12:40 Processing [49/54]\n",
      "12:40 Original label: Nikki_Nikkis car\n",
      "12:40 Objects to detect: ['Nikki', 'Nikkis car']\n",
      "12:40 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Nikki_and_Nikkis car/Nikki_Nikkis car_5_positive.png\n",
      "12:40   Mapped 'Nikki' -> 'Nikki-woman'\n",
      "12:40   Mapped 'Nikkis car' -> 'Nikkis car-car'\n",
      "12:40   Found 2 valid objects: ['Nikki-woman', 'Nikkis car-car']\n",
      "12:40 Applied sam mask on dino features\n",
      "12:40   Detected 'Nikki-woman' with score 0.730\n",
      "12:40   Detected 'Nikkis car-car' with score 0.491\n",
      "12:40 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"NIKKI\" and the entity enclosed in a red box is called \"NIKKI'S CAR\". Never mention the boxes and their colors. Answer the following question: What is Nikki’s posture and what is Nikkis car set up for?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:40 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:40 Ground Truth: Nikki is Leaning forward toward the camera and Nikkis car is set up for camping or sleeping..\n",
      "12:40 Prediction: Nikki is standing beside her car with one hand holding a drink and the other gesturing. Nikki's car has its door open, and it appears to be set up for a road trip or outdoor adventure, with items like a cooler and possibly camping\n",
      "12:40 Result: ✗ INCORRECT\n",
      "12:40 \n",
      "================================================================================\n",
      "12:40 Processing [50/54]\n",
      "12:40 Original label: Gab_Gabs puppy lili\n",
      "12:40 Objects to detect: ['Gab', 'Gabs puppy lili']\n",
      "12:40 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Gab_and_Gabs puppy lili/Gab_Gabs puppy lili_1_positive.png\n",
      "12:40   Mapped 'Gab' -> 'Gab-woman'\n",
      "12:40   Mapped 'Gabs puppy lili' -> 'Gabs puppy lili-dog'\n",
      "12:40   Found 2 valid objects: ['Gab-woman', 'Gabs puppy lili-dog']\n",
      "12:40 Applied sam mask on dino features\n",
      "12:40   Detected 'Gab-woman' with score 0.137\n",
      "12:40   Detected 'Gabs puppy lili-dog' with score 0.292\n",
      "12:40 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"GAB\" and the entity enclosed in a red box is called \"GAB'S PUPPY LILI\". Never mention the boxes and their colors. Answer the following question: What is Gab doing and what is Gabs puppy lili's expression ?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:40 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:40 Ground Truth: Gab is cuddling Gabs puppy lili which has a calm or curious expression.\n",
      "12:40 Prediction: Gab is holding her puppy, Lili, close to her face. Lili appears to have a calm and relaxed expression.\n",
      "12:40 Result: ✓ CORRECT\n",
      "12:40 \n",
      "================================================================================\n",
      "12:40 Processing [51/54]\n",
      "12:40 Original label: Gab_Gabs puppy lili\n",
      "12:40 Objects to detect: ['Gab', 'Gabs puppy lili']\n",
      "12:40 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Gab_and_Gabs puppy lili/Gab_Gabs puppy lili_2_positive.png\n",
      "12:40   Mapped 'Gab' -> 'Gab-woman'\n",
      "12:40   Mapped 'Gabs puppy lili' -> 'Gabs puppy lili-dog'\n",
      "12:40   Found 2 valid objects: ['Gab-woman', 'Gabs puppy lili-dog']\n",
      "12:40 Applied sam mask on dino features\n",
      "12:40   Detected 'Gab-woman' with score 0.119\n",
      "12:40   Detected 'Gabs puppy lili-dog' with score 0.282\n",
      "12:40 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"GAB\" and the entity enclosed in a red box is called \"GAB'S PUPPY LILI\". Never mention the boxes and their colors. Answer the following question: What is Gab doing and what is Gabs puppy lili wearing?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:40 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:40 Ground Truth: Gab is holding Gabs puppy lili which wearing a red holiday sweater.\n",
      "12:40 Prediction: Gab is holding her puppy, Lili. Lili is wearing a red outfit.\n",
      "12:40 Result: ✓ CORRECT\n",
      "12:40 \n",
      "================================================================================\n",
      "12:40 Processing [52/54]\n",
      "12:40 Original label: Gab_Gabs puppy lili\n",
      "12:40 Objects to detect: ['Gab', 'Gabs puppy lili']\n",
      "12:40 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Gab_and_Gabs puppy lili/Gab_Gabs puppy lili_3_positive.png\n",
      "12:40   Mapped 'Gab' -> 'Gab-woman'\n",
      "12:40   Mapped 'Gabs puppy lili' -> 'Gabs puppy lili-dog'\n",
      "12:40   Found 2 valid objects: ['Gab-woman', 'Gabs puppy lili-dog']\n",
      "12:40 Applied sam mask on dino features\n",
      "12:40   Detected 'Gab-woman' with score 0.237\n",
      "12:40   Detected 'Gabs puppy lili-dog' with score 0.289\n",
      "12:40 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"GAB\" and the entity enclosed in a red box is called \"GAB'S PUPPY LILI\". Never mention the boxes and their colors. Answer the following question: What is Gab wearing and where is Gabs puppy lili?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:40 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:40 Ground Truth: Gab is wearing a light pink top and Gabs puppy lili is sitting on a bed with two people.\n",
      "12:40 Prediction: Gab is wearing a light-colored shirt and a cap. Gabs puppy Lili is on the bed next to Gab.\n",
      "12:40 Result: ✗ INCORRECT\n",
      "12:40 \n",
      "================================================================================\n",
      "12:40 Processing [53/54]\n",
      "12:40 Original label: Gab_Gabs puppy lili\n",
      "12:40 Objects to detect: ['Gab', 'Gabs puppy lili']\n",
      "12:40 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Gab_and_Gabs puppy lili/Gab_Gabs puppy lili_4_positive.png\n",
      "12:40   Mapped 'Gab' -> 'Gab-woman'\n",
      "12:40   Mapped 'Gabs puppy lili' -> 'Gabs puppy lili-dog'\n",
      "12:40   Found 2 valid objects: ['Gab-woman', 'Gabs puppy lili-dog']\n",
      "12:40 Applied sam mask on dino features\n",
      "12:40   Detected 'Gab-woman' with score 0.177\n",
      "12:40   Detected 'Gabs puppy lili-dog' with score 0.300\n",
      "12:40 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"GAB\" and the entity enclosed in a red box is called \"GAB'S PUPPY LILI\". Never mention the boxes and their colors. Answer the following question: What is Gab wearing and what is Gabs puppy lili doing?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:40 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:40 Ground Truth: gab is wearing a white top and Gabs puppy lili is squirming or moving its paw.\n",
      "12:40 Prediction: Gab is wearing a white top, and Lili, Gab's puppy, is wearing a red and white outfit.\n",
      "12:40 Result: ✗ INCORRECT\n",
      "12:40 \n",
      "================================================================================\n",
      "12:40 Processing [54/54]\n",
      "12:40 Original label: Gab_Gabs puppy lili\n",
      "12:40 Objects to detect: ['Gab', 'Gabs puppy lili']\n",
      "12:40 Image: /fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/test/Gab_and_Gabs puppy lili/Gab_Gabs puppy lili_5_positive.png\n",
      "12:40   Mapped 'Gab' -> 'Gab-woman'\n",
      "12:40   Mapped 'Gabs puppy lili' -> 'Gabs puppy lili-dog'\n",
      "12:40   Found 2 valid objects: ['Gab-woman', 'Gabs puppy lili-dog']\n",
      "12:40 Applied sam mask on dino features\n",
      "12:40   Detected 'Gab-woman' with score 0.124\n",
      "12:40   Detected 'Gabs puppy lili-dog' with score 0.296\n",
      "12:40 Question: USER: <image>\n",
      "In this image, the entity enclosed in a blue box is called \"GAB\" and the entity enclosed in a red box is called \"GAB'S PUPPY LILI\". Never mention the boxes and their colors. Answer the following question: Where is Gab looking and what is Gabs puppy lili looking at ?\n",
      "ASSISTANT:\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "12:40 HTTP Request: POST https://tme-dna-llms-rnd-ai-research.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "12:40 Ground Truth: Gab has her eyes closed while Gabs puppy lili is looking off into the distance.\n",
      "12:40 Prediction: Gab is looking at her puppy, Lili, while Lili is looking up at Gab.\n",
      "12:40 Result: ✗ INCORRECT\n",
      "12:40 \n",
      "================================================================================\n",
      "12:40 PER-OBJECT RESULTS\n",
      "12:40 ================================================================================\n",
      "12:40 Casey_Caseys boosted board              :   3/  4 =  75.00%\n",
      "12:40 Zak_Zaks dog kona                       :   3/  5 =  60.00%\n",
      "12:40 Nikki_Nikkis camper bag                 :   1/  5 =  20.00%\n",
      "12:40 Zak_Zaks dog coffee                     :   2/  5 =  40.00%\n",
      "12:40 Sherry_Sherrys road bike                :   3/  5 =  60.00%\n",
      "12:40 Casey_Caseys son                        :   1/  5 =  20.00%\n",
      "12:40 Blippi_Blippis shoes                    :   2/  5 =  40.00%\n",
      "12:40 Alex_Alexs everyday bag                 :   4/  5 =  80.00%\n",
      "12:40 Alex_Alexs hat                          :   4/  5 =  80.00%\n",
      "12:40 Nikki_Nikkis car                        :   1/  5 =  20.00%\n",
      "12:40 Gab_Gabs puppy lili                     :   2/  5 =  40.00%\n",
      "12:40 \n",
      "OVERALL ACCURACY: 26/54 = 48.15%\n",
      "12:40 \n",
      "Results saved to results/vqa/OpenGVLab/InternVL3-14B/Thursday_05_12_37_PM/results_summary.json\n",
      "12:40 Evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simplified VQA validation using dataloader.\n",
    "\n",
    "This script uses the improved dataloader which builds the dataset\n",
    "directly from the VQA JSON file, ensuring only images with QA pairs are loaded.\n",
    "\"\"\"\n",
    "\n",
    "print('started')\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import tempfile\n",
    "from collections import defaultdict\n",
    "from utils import setup_args, Azure_evaluate, get_cat_folders_from_features, draw_bounding_box, mask_to_normalized_bbox, get_query, get_objects_features, apply_mask_dino, get_mask_for_gt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import glob\n",
    "import copy\n",
    "from loader import get_dataloader\n",
    "from model import Extractor, Personalized_InternVL\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "print('import finished')\n",
    "\n",
    "# === Setup ===\n",
    "args = setup_args()\n",
    "args.dataset = 'this-is-my'\n",
    "args.task = 'vqa'\n",
    "args.features_folder = '/shared/home/SSO3984/Pekit-github-dev/features_folder/'\n",
    "args.multi_concept = True\n",
    "args.device_ids = [7]\n",
    "args.vlm_model = \"OpenGVLab/InternVL3-14B\"\n",
    "args.n_training_views = 5\n",
    "#args.variation = \"augment\"\n",
    "#args.n_augment = 10\n",
    "args.grounding_sam = True\n",
    "args.split = 'test'  # Set to validation/test split\n",
    "args.batch_size = 1  # Process one at a time for VQA\n",
    "args.shuffle = False  # Don't shuffle for consistent results\n",
    "args.num_workers = 0  # Simpler for debugging\n",
    "# Override JSON path if needed\n",
    "args.json_path = \"/fsx/ad/vlm/github_datasets_test/This-is-My-Img/Multi-concept/this-is-my-visual-qa-multi-concept.json\"\n",
    "\n",
    "if args.variation == 'normal':\n",
    "    args.n_augment = 1\n",
    "\n",
    "colors = ['blue', 'red', 'green', 'purple', 'orange', 'pink', 'gray', 'yellow']\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(message)s',\n",
    "    datefmt='%H:%M'\n",
    ")\n",
    "\n",
    "# === Load dataloader ===\n",
    "logging.info(\"Loading dataloader...\")\n",
    "dataloader, my_objects, context_pool = get_dataloader(args)\n",
    "logging.info(f\"Dataloader loaded with {len(dataloader.dataset)} VQA samples\")\n",
    "logging.info(f\"Found {len(my_objects)} object categories\")\n",
    "\n",
    "# === Initialize models ===\n",
    "logging.info(\"Loading models...\")\n",
    "mask_extractor = Extractor(args)\n",
    "azure = Azure_evaluate ()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 'InternVL' in args.vlm_model:\n",
    "    vlm_model = Personalized_InternVL(args)\n",
    "else:\n",
    "    sys.exit(f\"{args.vlm_model} is not supported\")\n",
    "\n",
    "# === Load object features ===\n",
    "logging.info(\"Loading object features...\")\n",
    "# Get training views from the feature folder\n",
    "cat_folders = get_cat_folders_from_features(args)\n",
    "feature_objects = [os.path.basename(folder) for folder in cat_folders]\n",
    "\n",
    "all_obj_files, all_obj_features = get_objects_features(args, my_objects)\n",
    "logging.info(f\"Features loaded for {len(feature_objects)} objects\")\n",
    "\n",
    "# Debug: Print feature objects\n",
    "logging.info(f\"Feature objects found: {feature_objects}\")\n",
    "for obj in feature_objects:\n",
    "    logging.info(f\"  - '{obj}'\")\n",
    "\n",
    "# Create a mapping from object name to features\n",
    "object_to_features = {}\n",
    "for idx, obj_name in enumerate(feature_objects):\n",
    "    object_to_features[obj_name] = all_obj_features[idx].unsqueeze(0)\n",
    "\n",
    "# Create name mapping for multi-concept lookups\n",
    "# Maps \"Casey\" -> \"Casey-man\", \"Alex\" -> \"Alex-woman\", etc.\n",
    "name_to_full_object = {}\n",
    "for obj in feature_objects:\n",
    "    # Extract base name (before hyphen)\n",
    "    if '-' in obj:\n",
    "        base_name = obj.split('-')[0]\n",
    "        # Handle possessive forms: \"Caseys\" -> \"Casey\"\n",
    "        if base_name.endswith('s') and len(base_name) > 1:\n",
    "            base_name_without_s = base_name[:-1]\n",
    "            if base_name_without_s not in name_to_full_object:\n",
    "                name_to_full_object[base_name_without_s] = obj\n",
    "        if base_name not in name_to_full_object:\n",
    "            name_to_full_object[base_name] = obj\n",
    "    # Also add the full object name without suffix for object lookups\n",
    "    # e.g., \"Caseys boosted board-skateboard\" -> also map \"Caseys boosted board\"\n",
    "    if '-' in obj:\n",
    "        base_obj = '-'.join(obj.split('-')[:-1])  # Remove suffix after last hyphen\n",
    "        if base_obj not in name_to_full_object:\n",
    "            name_to_full_object[base_obj] = obj\n",
    "\n",
    "logging.info(f\"Name mapping created: {name_to_full_object}\")\n",
    "\n",
    "# === Setup results tracking ===\n",
    "results_by_object = defaultdict(lambda: {'correct': 0, 'total': 0})\n",
    "all_correct = 0\n",
    "all_total = 0\n",
    "\n",
    "# Setup save path\n",
    "current_time = datetime.now()\n",
    "formatted_time = current_time.strftime(\"%A_%d_%I_%M_%p\")\n",
    "save_path = os.path.join(args.save_folder, args.task, args.vlm_model, formatted_time)\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "logging.info(f\"Results will be saved to: {save_path}\")\n",
    "\n",
    "# === Main evaluation loop ===\n",
    "logging.info(\"\\n\" + \"=\" * 80)\n",
    "logging.info(\"Starting VQA evaluation\")\n",
    "logging.info(\"=\" * 80)\n",
    "\n",
    "for batch_idx, batch in enumerate(dataloader):\n",
    "    if batch is None:\n",
    "        continue\n",
    "    \n",
    "    # Unpack batch (batch size is 1)\n",
    "    # Returns: img, img_dino, path, label, question, answer, None, label_map, open_question, full_answer\n",
    "    imgs, imgs_dino, paths, labels, questions, answers, _, label_maps, open_questions, full_answers = batch\n",
    "    \n",
    "    # Get single items from batch\n",
    "    img_array = imgs[0]  # Already numpy array\n",
    "    img_dino_array = imgs_dino[0]  # Already numpy array\n",
    "    img_path = paths[0]\n",
    "    obj_name = labels[0]\n",
    "    question = questions[0]\n",
    "    answer = answers[0]\n",
    "    label_map = label_maps[0] if label_maps[0] is not None else {}\n",
    "    \n",
    "    if question is None or answer is None:\n",
    "        logging.warning(f\"Skipping {img_path} - missing QA data\")\n",
    "        continue\n",
    "    \n",
    "    # Parse multi-concept object names\n",
    "    # Multi-concept format: \"Person_Persons object\" (underscore separator)\n",
    "    # Single concept format: \"Object-type\" (hyphen separator, no underscore)\n",
    "    parts = obj_name.split('_', 1)\n",
    "    \n",
    "    if len(parts) == 2:\n",
    "        # Multi-concept case: split into individual objects\n",
    "        object_names = parts  # e.g., [\"Casey\", \"Caseys boosted board\"]\n",
    "    else:\n",
    "        # Single concept case\n",
    "        object_names = [obj_name]  # e.g., [\"Alexs everyday bag-bag\"]\n",
    "    \n",
    "    logging.info(f\"\\n{'=' * 80}\")\n",
    "    logging.info(f\"Processing [{batch_idx + 1}/{len(dataloader)}]\")\n",
    "    logging.info(f\"Original label: {obj_name}\")\n",
    "    logging.info(f\"Objects to detect: {object_names}\")\n",
    "    logging.info(f\"Image: {img_path}\")\n",
    "    \n",
    "    # Get features for ALL objects\n",
    "    obj_features_list = []\n",
    "    valid_objects = []\n",
    "    valid_object_display_names = []  # For display purposes (with label_map applied)\n",
    "    \n",
    "    for obj in object_names:\n",
    "        # Try direct match first\n",
    "        matched_obj = obj\n",
    "        \n",
    "        # If not found, try to map base name to full name\n",
    "        if obj not in object_to_features:\n",
    "            # Try name mapping (e.g., \"Casey\" -> \"Casey-man\")\n",
    "            if obj in name_to_full_object:\n",
    "                matched_obj = name_to_full_object[obj]\n",
    "                logging.info(f\"  Mapped '{obj}' -> '{matched_obj}'\")\n",
    "            else:\n",
    "                logging.warning(f\"  Object '{obj}' not found in feature list. Skipping this object.\")\n",
    "                continue\n",
    "        \n",
    "        if matched_obj not in object_to_features:\n",
    "            logging.warning(f\"  Object '{matched_obj}' not found in feature list. Skipping this object.\")\n",
    "            continue\n",
    "            \n",
    "        obj_features_list.append(object_to_features[matched_obj])\n",
    "        valid_objects.append(matched_obj)\n",
    "        \n",
    "        # Get display name (apply label_map if available)\n",
    "        display_name = label_map.get(obj, obj) if label_map else obj\n",
    "        valid_object_display_names.append(display_name)\n",
    "    \n",
    "    if len(obj_features_list) == 0:\n",
    "        logging.warning(f\"  No valid objects found. Skipping entire sample.\")\n",
    "        continue\n",
    "    \n",
    "    logging.info(f\"  Found {len(valid_objects)} valid objects: {valid_objects}\")\n",
    "    \n",
    "    # Concatenate all object features\n",
    "    obj_features = torch.cat(obj_features_list, dim=0)\n",
    "    \n",
    "    # Convert numpy back to PIL for processing\n",
    "    img_raw = Image.fromarray(img_array.astype(np.uint8))\n",
    "    \n",
    "    # Prepare image batches for DINO and SAM\n",
    "    dino_image_batch = [img_dino_array]\n",
    "    sam_image_batch = [img_dino_array]\n",
    "    \n",
    "    # Get DinoV2 features\n",
    "    dino_img_features = mask_extractor.forward_dino(dino_image_batch)\n",
    "    \n",
    "    # Get SAM masks\n",
    "    sam_masks = mask_extractor.forward_grounding_dino(sam_image_batch, ['object.'])\n",
    "    \n",
    "    # Get the mean Dino features for each mask\n",
    "    category_features = apply_mask_dino(args, sam_masks, dino_img_features[0])\n",
    "    category_features = torch.stack([x.mean(dim=0) for x in category_features])\n",
    "    \n",
    "    # Find best matching masks for ALL objects\n",
    "    bboxes = []\n",
    "    bbox_img = copy.deepcopy(img_raw)\n",
    "    \n",
    "    for idx, obj in enumerate(valid_objects):\n",
    "        obj_feat = obj_features_list[idx]\n",
    "        final_mask, max_score = get_mask_for_gt(args, category_features, sam_masks[0], obj_feat)\n",
    "        \n",
    "        bbox, bbox_raw = mask_to_normalized_bbox(final_mask)\n",
    "        bboxes.append(bbox)\n",
    "        \n",
    "        # Draw bounding box with different color for each object\n",
    "        bbox_img = draw_bounding_box(bbox_img, [bbox], [colors[idx]])\n",
    "        logging.info(f\"  Detected '{valid_objects[idx]}' with score {max_score:.3f}\")\n",
    "    \n",
    "    # Generate prompt with ALL detected objects\n",
    "    # Use display names for the prompt\n",
    "    prompts = get_query(args, valid_object_display_names, colors[:len(valid_objects)], question, None, None)\n",
    "    logging.info(f\"Question: {prompts}\")\n",
    "\n",
    "    \n",
    "    # Save bbox image to temporary file\n",
    "    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_file:\n",
    "        tmp_path = tmp_file.name\n",
    "        bbox_img.save(tmp_path)\n",
    "    \n",
    "    try:\n",
    "        #import pdb;pdb.set_trace()\n",
    "        response = vlm_model(tmp_path, [prompts])\n",
    "    finally:\n",
    "        # Clean up temporary file\n",
    "        if os.path.exists(tmp_path):\n",
    "            os.remove(tmp_path)\n",
    "    \n",
    "    # Parse answer - check if multiple choice or open-ended\n",
    "    if 'A.' in question or 'B.' in question:\n",
    "        # Multiple choice - extract letter\n",
    "        predicted_answer = None\n",
    "        response_lower = response.lower().strip()\n",
    "        \n",
    "        # Try to extract answer letter\n",
    "        if response_lower.startswith('a'):\n",
    "            predicted_answer = 'A'\n",
    "        elif response_lower.startswith('b'):\n",
    "            predicted_answer = 'B'\n",
    "        elif 'a.' in response_lower or 'a)' in response_lower:\n",
    "            predicted_answer = 'A'\n",
    "        elif 'b.' in response_lower or 'b)' in response_lower:\n",
    "            predicted_answer = 'B'\n",
    "        \n",
    "        # Extract correct answer letter from answer string (e.g., \"A.option text\")\n",
    "        correct_letter = answer[0] if answer and len(answer) > 0 else None\n",
    "        is_correct = (predicted_answer == correct_letter)\n",
    "    else:\n",
    "        # Open-ended - simple string matching\n",
    "        llm_answer = azure.evaluate_answer(question, response, answer)\n",
    "        #print('LLm Answer:',llm_answer)\n",
    "        if 'yes' in llm_answer.lower():\n",
    "            is_correct = True\n",
    "        elif 'no' in llm_answer.lower():\n",
    "            is_correct = False\n",
    "    \n",
    "    correctness = \"✓ CORRECT\" if is_correct else \"✗ INCORRECT\"\n",
    "    logging.info(f\"Ground Truth: {answer}\")\n",
    "    logging.info(f\"Prediction: {response}\")\n",
    "    logging.info(f\"Result: {correctness}\")\n",
    "    \n",
    "    # Update counters (use original obj_name for tracking)\n",
    "    results_by_object[obj_name]['correct'] += int(is_correct)\n",
    "    results_by_object[obj_name]['total'] += 1\n",
    "    all_correct += int(is_correct)\n",
    "    all_total += 1\n",
    "    \n",
    "    # Save detailed results\n",
    "    with open(os.path.join(save_path, 'results_vqa.txt'), 'a') as file:\n",
    "        file.write('#' * 80 + '\\n')\n",
    "        file.write(f'IMG Path: {img_path}\\n')\n",
    "        file.write(f'Objects: {obj_name} -> {valid_objects}\\n')\n",
    "        file.write(f'Question: {question}\\n')\n",
    "        file.write(f'Ground Truth: {answer}\\n')\n",
    "        file.write(f'Prediction: {response}\\n')\n",
    "        file.write(f'Result: {correctness}\\n')\n",
    "    \n",
    "    if not is_correct and hasattr(args, 'show') and args.show:\n",
    "        plt.imshow(bbox_img)\n",
    "        plt.title(f\"Q: {question}\\nGT: {answer}\\nPred: {response}\")\n",
    "        plt.show()\n",
    "\n",
    "# === Aggregate results ===\n",
    "logging.info(\"\\n\" + \"=\" * 80)\n",
    "logging.info(\"PER-OBJECT RESULTS\")\n",
    "logging.info(\"=\" * 80)\n",
    "\n",
    "per_object = {}\n",
    "for obj, res in results_by_object.items():\n",
    "    acc = res['correct'] / res['total'] * 100 if res['total'] > 0 else 0\n",
    "    logging.info(f\"{obj:40s}: {res['correct']:3d}/{res['total']:3d} = {acc:6.2f}%\")\n",
    "    per_object[obj] = {'correct': res['correct'], 'total': res['total'], 'accuracy': acc}\n",
    "\n",
    "overall_acc = all_correct / all_total * 100 if all_total > 0 else 0\n",
    "logging.info(f\"\\nOVERALL ACCURACY: {all_correct}/{all_total} = {overall_acc:.2f}%\")\n",
    "\n",
    "# === Save results ===\n",
    "results_dict = {\n",
    "    'per_object': per_object,\n",
    "    'overall': {'correct': all_correct, 'total': all_total, 'accuracy': overall_acc}\n",
    "}\n",
    "\n",
    "results_json_path = os.path.join(save_path, 'results_summary.json')\n",
    "with open(results_json_path, 'w') as f:\n",
    "    json.dump(results_dict, f, indent=2)\n",
    "\n",
    "logging.info(f\"\\nResults saved to {results_json_path}\")\n",
    "\n",
    "# Also save in the original format for compatibility\n",
    "with open(os.path.join(save_path, 'results_vqa.txt'), 'a') as file:\n",
    "    file.write('\\n' + '=' * 80 + '\\n')\n",
    "    file.write('SUMMARY\\n')\n",
    "    file.write('=' * 80 + '\\n')\n",
    "    file.write(f'Total Images: {all_total}\\n')\n",
    "    file.write(f'Correct Images: {all_correct}\\n')\n",
    "    file.write(f'Accuracy: {overall_acc:.2f}%\\n')\n",
    "\n",
    "logging.info(\"Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeroshot_github",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
